# HexSoftwares Internship - Week 1
## Sentiment Analysis: Customer Feedback

In this project, two datasets are combined to create a larger and more diverse training set, enhancing the modelâ€™s accuracy compared to using a single dataset.
Several preprocessing techniques are used to improve the performance of NLP models and ensuring the data is clean and suitable for training. Some of these techniques include:
- Removing unwanted characters and special symbols
- Eliminating stop words (commonly used words like "and," "the," etc.)
- Applying stemming and lemmatization to reduce words to their root forms
- Encoding textual data
- Padding sequences to ensure uniform input lengths.

The models used for classification are:
- Naive Bayes Classifier (NBC): Chosen due to the relatively small size of the dataset.
- Recurrent Neural Network (RNN): Selected for its practicality and scalability, especially with more complex datasets.

The results of both methods are then compared to evaluate their performance.
